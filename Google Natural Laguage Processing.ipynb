{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name\n",
    "filepath = \"********\"\n",
    "output_filepath = \"********\"\n",
    "text_file_name = \"*******.txt\"\n",
    "credentials = \"*******.json\"\n",
    "bucket_name = \"*******\"\n",
    "source_file_name = filepath + text_file_name\n",
    "destination_blob_name = text_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uplodaing the data to the cloud\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name, credentials):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client.from_service_account_json(credentials)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "upload_blob(bucket_name, source_file_name, destination_blob_name,credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Analyzing Sentiment from Google Cloud Storage\n",
    "gcs_uri = 'gs://*******/' + text_file_name\n",
    "client = language.LanguageServiceClient.from_service_account_json(credentials)\n",
    "\n",
    "# Instantiates a plain text document.\n",
    "document = types.Document(\n",
    "    gcs_content_uri=gcs_uri,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects sentiment in the document. You can also analyze HTML with:\n",
    "#   document.type == enums.Document.Type.HTML\n",
    "sentiment = client.analyze_sentiment(document).document_sentiment\n",
    "\n",
    "print('Score: {}'.format(sentiment.score))\n",
    "print('Magnitude: {}'.format(sentiment.magnitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Analyzing Entities\n",
    "gcs_uri = 'gs://*******/' + text_file_name\n",
    "client = language.LanguageServiceClient.from_service_account_json(credentials)\n",
    "\n",
    "# Instantiates a plain text document.\n",
    "document = types.Document(\n",
    "    gcs_content_uri=gcs_uri,\n",
    "    type=enums.Document.Type.PLAIN_TEXT)\n",
    "\n",
    "# Detects sentiment in the document. You can also analyze HTML with:\n",
    "#   document.type == enums.Document.Type.HTML\n",
    "entities = client.analyze_entities(document).entities\n",
    "\n",
    "for entity in entities:\n",
    "    entity_type = enums.Entity.Type(entity.type)\n",
    "    print('=' * 20)\n",
    "    print(u'{:<16}: {}'.format('name', entity.name))\n",
    "    print(u'{:<16}: {}'.format('type', entity_type.name))\n",
    "    print(u'{:<16}: {}'.format('salience', entity.salience))\n",
    "    print(u'{:<16}: {}'.format('wikipedia_url',\n",
    "          entity.metadata.get('wikipedia_url', '-')))\n",
    "    print(u'{:<16}: {}'.format('mid', entity.metadata.get('mid', '-')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Analyzing Entity Sentiment\n",
    "# Detect and send native Python encoding to receive correct word offsets.\n",
    "encoding = enums.EncodingType.UTF32\n",
    "if sys.maxunicode == 65535:\n",
    "    encoding = enums.EncodingType.UTF16\n",
    "\n",
    "result = client.analyze_entity_sentiment(document, encoding)\n",
    "\n",
    "for entity in result.entities:\n",
    "    print(u'Name: \"{}\"'.format(entity.name))\n",
    "    for mention in entity.mentions:\n",
    "        print(u'  Begin Offset : {}'.format(mention.text.begin_offset))\n",
    "        print(u'  Content : {}'.format(mention.text.content))\n",
    "        print(u'  Magnitude : {}'.format(mention.sentiment.magnitude))\n",
    "        print(u'  Sentiment : {}'.format(mention.sentiment.score))\n",
    "        print(u'  Type : {}'.format(mention.type))\n",
    "    print(u'Salience: {}'.format(entity.salience))\n",
    "    print(u'Sentiment: {}\\n'.format(entity.sentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
